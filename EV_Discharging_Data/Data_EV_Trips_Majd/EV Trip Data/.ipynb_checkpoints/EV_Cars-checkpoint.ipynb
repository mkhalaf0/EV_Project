{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f1d7f6",
   "metadata": {},
   "source": [
    "# extracting data from the gps tracker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68407191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:414 Pom 77]',\n",
       " '',\n",
       " '< My Trips Trip S)',\n",
       " '',\n",
       " '03 Apr 2024 Long Trip',\n",
       " '',\n",
       " 'Time Summary',\n",
       " '',\n",
       " '01 hO5m55s',\n",
       " '',\n",
       " 'Distance',\n",
       " '',\n",
       " '53.8mile',\n",
       " '',\n",
       " 'Travel Time Max. Speed',\n",
       " '',\n",
       " '01 n05m23s Sach',\n",
       " '',\n",
       " 'Stopped Time Avg Speed',\n",
       " '',\n",
       " '00,,32; 49 Omph',\n",
       " '',\n",
       " 'Max. Altitude Avg Altitude',\n",
       " '',\n",
       " '15278 920:',\n",
       " '',\n",
       " 'Map & Graphs',\n",
       " '',\n",
       " '> %',\n",
       " '',\n",
       " 'Trip Log Trip Settings',\n",
       " '']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a865f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\3314185937.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:/Users/msikh/EV_Project/EV_Discharging_Data/NEUTC/EV Trip Data/Data_2/GPS App/Data_EV_trip_GPS_APP.csv\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Setting the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image, lang='eng', config='--psm 6')\n",
    "    return text\n",
    "\n",
    "# Function to correct the speed format after the semicolon\n",
    "def correct_speed_format(text):\n",
    "    # Find the part of the text that matches the pattern after the semicolon\n",
    "    match = re.search(r';\\s*([\\d\\s.,]+)\\s*', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        # Extract the numeric part and clean it\n",
    "        speed = match.group(1).replace(',', '.').replace(' ', '.')\n",
    "        # Return only the corrected speed with \"mph\"\n",
    "        return f'{speed} mph'\n",
    "    return text\n",
    "\n",
    "def process_lines(lines):\n",
    "    # Initialize the dictionary\n",
    "    data_dict = {'Avg Speed': '', 'Distance': ''}\n",
    "\n",
    "    # Iterate through the list to find the element containing \"mile\" and \"mpn\"\n",
    "    for element in lines:\n",
    "        if 'mile' in element.lower():\n",
    "            data_dict['Distance'] = element\n",
    "\n",
    "        if 'mpn' in element.lower() or 'mph' in element.lower():\n",
    "            corrected_speed = correct_speed_format(element)\n",
    "            data_dict['Avg Speed'] = corrected_speed\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def process_text(ocr_text, lines):\n",
    "    # Process the lines to find Distance and Avg Speed\n",
    "    data_dict = process_lines(lines)\n",
    "\n",
    "    # Regex patterns to extract other relevant data\n",
    "    patterns = {\n",
    "        \"Time Summary\": r\"Time Summary\\s*([\\d\\w\\s]+?)(?=\\n|$)\",\n",
    "        \"Max Altitude\": r\"Max Altitude\\s*([\\d,]+)\",\n",
    "        \"Avg Altitude\": r\"Avg Altitude\\s*([\\d,]+)\"\n",
    "    }\n",
    "\n",
    "    # Extracting and cleaning the data\n",
    "    extracted_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        # Search using the pattern\n",
    "        match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            if key in [\"Max Altitude\", \"Avg Altitude\"]:\n",
    "                value = value.replace(\":\", \"\").strip() + \" ft\"  # Correct format and OCR error\n",
    "            extracted_data[key] = value\n",
    "\n",
    "    # Merge the dictionaries\n",
    "    extracted_data.update(data_dict)\n",
    "\n",
    "    # Further process for elevation gain\n",
    "    pattern = r\"Avg Altitude\\s*([\\d,]+)\\s*:\\s*([\\d,]+)\"\n",
    "    match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        avg_altitude_first = match.group(1).replace(',', '').strip()\n",
    "        avg_altitude_next = match.group(2).replace(',', '').strip()\n",
    "        extracted_data['Avg Altitude'] = avg_altitude_next + \" ft\"\n",
    "        extracted_data[\"Elevation Gain\"] = str(int(avg_altitude_next.replace(\" ft\", \"\")) - int(avg_altitude_first.replace(\" ft\", \"\"))) + \" ft\"\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# DataFrame to store all data cumulatively\n",
    "cumulative_data_df = pd.DataFrame()\n",
    "\n",
    "def upload_action():\n",
    "    file_paths = filedialog.askopenfilenames()\n",
    "    global cumulative_data_df\n",
    "    for path in file_paths:\n",
    "        text = process_image(path)\n",
    "        lines = text.split('\\n')\n",
    "        data = process_text(text, lines)\n",
    "        data['Image'] = os.path.basename(path)\n",
    "        cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
    "    \n",
    "    result_text.delete('1.0', tk.END)  # Clear existing text\n",
    "    result_text.insert(tk.END, cumulative_data_df.to_string(index=False))  # Display dataframe as string in text widget\n",
    "\n",
    "def save_csv():\n",
    "    save_path = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    if save_path:\n",
    "        global cumulative_data_df\n",
    "        cumulative_data_df.to_csv(save_path, index=False)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "        cumulative_data_df = pd.DataFrame()  # Reset DataFrame after saving\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"EV_IMAGE_TEXT_Extractor\")\n",
    "\n",
    "# Button to upload images\n",
    "upload_btn = tk.Button(root, text=\"Upload Images\", command=upload_action)\n",
    "upload_btn.pack()\n",
    "\n",
    "# Button to save CSV\n",
    "save_btn = tk.Button(root, text=\"Save CSV\", command=save_csv)\n",
    "save_btn.pack()\n",
    "\n",
    "# Text widget to display results\n",
    "result_text = tk.Text(root, height=20, width=80)\n",
    "result_text.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bad34c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Avg Speed': '49. mph', 'Distance': '53.8mile'}\n"
     ]
    }
   ],
   "source": [
    "lines\n",
    "# Initialize the dictionary\n",
    "data_dict = {'Avg Speed': '',\"Distance\":\"\"}\n",
    "# Initialize the dictionary\n",
    "data_dict = {'Avg Speed': '', 'Distance': ''}\n",
    "\n",
    "# Function to correct the speed format after the semicolon\n",
    "def correct_speed_format(text):\n",
    "    # Find the part of the text that matches the pattern after the semicolon\n",
    "    match = re.search(r';\\s*([\\d\\s.,]+)\\s*', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        # Extract the numeric part and clean it\n",
    "        speed = match.group(1).replace(',', '.').replace(' ', '.')\n",
    "        # Replace the original part with the corrected format\n",
    "        corrected_text = f\"{speed} mph\"\n",
    "        return corrected_text\n",
    "    return text\n",
    "\n",
    "# Iterate through the list to find the element containing \"mile\" and \"mpn\"\n",
    "for element in lines:\n",
    "    if 'mile' in element.lower():\n",
    "        data_dict['Distance'] = element\n",
    "        \n",
    "    if 'mpn' in element.lower() or 'mph' in element.lower():\n",
    "        corrected_element = correct_speed_format(element)\n",
    "        data_dict['Avg Speed'] = corrected_element\n",
    "\n",
    "# Print the dictionary\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6dbfb8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time Summary': '01 hO7m27s', 'Avg Speed': '', 'Max Altitude': '1,590 ft', 'Avg Altitude': '938 ft', 'Elevation Gain': '-652 ft'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# Path to the Tesseract-OCR executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "# Load the image\n",
    "image_path = '040324A.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform OCR on the image\n",
    "text = pytesseract.image_to_string(image, lang='eng')\n",
    "\n",
    "# Process the extracted text to get the relevant data\n",
    "lines = text.split(' ')\n",
    "\n",
    "def process_text(ocr_text,lines):\n",
    "    # Regex patterns to extract relevant data\n",
    "    patterns = {\n",
    "        \"Time Summary\": r\"Time Summary\\s*([\\d\\w\\s]+?)(?=\\n|$)\",\n",
    "        \"Distance\": r\"Distance\\s*([\\d\\.]+\\s*[a-zA-Z]+)+mile\",\n",
    "        \"Avg Speed\": r\"Avg Speed\\s*([\\d\\.]+\\s*[a-zA-Z]+)\",\n",
    "        \"Max Altitude\": r\"Avg Altitude\\s*([\\d,]+)\",\n",
    "        \"Avg Speed\": r\"Avg Speed\\s*([\\d\\w\\s:.]+?)(?=\\n|$)\",\n",
    "        \"Avg Altitude\": r\"Avg Altitude\\s*([\\d,]+)\"\n",
    "    }\n",
    "\n",
    "    # Extracting and cleaning the data\n",
    "    extracted_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        # Search using the pattern\n",
    "        match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            #if key == \"Avg Speed\":\n",
    "                #value = re.sub(r\"^\\d+\\.\\d+\\s*\", \"\", value)  # Remove unwanted prefix numbers\n",
    "                #value = value.replace(\"Sinpn\", \"mph\").replace(\" \", \".\").replace(\"..\", \"\")\n",
    "            if key in [\"Max Altitude\", \"Avg Altitude\"]:\n",
    "                value = value.replace(\":\", \"\").strip() + \" ft\"  # Correct format and OCR error\n",
    "            extracted_data[key] = value\n",
    "\n",
    "    # Further process for elevation gain\n",
    "    pattern = r\"Avg Altitude\\s*([\\d,]+)\\s*:\\s*([\\d,]+)\"\n",
    "    match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        avg_altitude_first = match.group(1).replace(',', '').strip()\n",
    "        avg_altitude_next = match.group(2).replace(',', '').strip()\n",
    "        extracted_data['Avg Altitude'] = avg_altitude_next + \" ft\"\n",
    "        extracted_data[\"Elevation Gain\"] = str(int(avg_altitude_next.replace(\" ft\", \"\")) - int(avg_altitude_first.replace(\" ft\", \"\"))) + \" ft\"\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "data = process_text(text,lines)\n",
    "\n",
    "# Show the DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ce982089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time Summary': '01 hO5m55s', 'Avg Altitude': '15278 ft', 'Avg Speed': '49. mph', 'Distance': '53.8mile'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the Tesseract-OCR executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Load the image\n",
    "image_path = '040324B-Copy1.PNG'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform OCR on the image\n",
    "text = pytesseract.image_to_string(image, lang='eng')\n",
    "\n",
    "# Split the text into lines\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# Function to correct the speed format after the semicolon\n",
    "def correct_speed_format(text):\n",
    "    # Find the part of the text that matches the pattern after the semicolon\n",
    "    match = re.search(r';\\s*([\\d\\s.,]+)\\s*', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        # Extract the numeric part and clean it\n",
    "        speed = match.group(1).replace(',', '.').replace(' ', '.')\n",
    "        # Return only the corrected speed with \"mph\"\n",
    "        return f'{speed} mph'\n",
    "    return text\n",
    "\n",
    "def process_lines(lines):\n",
    "    # Initialize the dictionary\n",
    "    data_dict = {'Avg Speed': '', 'Distance': ''}\n",
    "\n",
    "    # Iterate through the list to find the element containing \"mile\" and \"mpn\"\n",
    "    for element in lines:\n",
    "        if 'mile' in element.lower():\n",
    "            data_dict['Distance'] = element\n",
    "\n",
    "        if 'mpn' in element.lower() or 'mph' in element.lower():\n",
    "            corrected_speed = correct_speed_format(element)\n",
    "            data_dict['Avg Speed'] = corrected_speed\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def process_text(ocr_text, lines):\n",
    "    # Process the lines to find Distance and Avg Speed\n",
    "    data_dict = process_lines(lines)\n",
    "\n",
    "    # Regex patterns to extract other relevant data\n",
    "    patterns = {\n",
    "        \"Time Summary\": r\"Time Summary\\s*([\\d\\w\\s]+?)(?=\\n|$)\",\n",
    "        \"Max Altitude\": r\"Max Altitude\\s*([\\d,]+)\",\n",
    "        \"Avg Altitude\": r\"Avg Altitude\\s*([\\d,]+)\"\n",
    "    }\n",
    "\n",
    "    # Extracting and cleaning the data\n",
    "    extracted_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        # Search using the pattern\n",
    "        match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            if key in [\"Max Altitude\", \"Avg Altitude\"]:\n",
    "                value = value.replace(\":\", \"\").strip() + \" ft\"  # Correct format and OCR error\n",
    "            extracted_data[key] = value\n",
    "\n",
    "    # Merge the dictionaries\n",
    "    extracted_data.update(data_dict)\n",
    "\n",
    "    # Further process for elevation gain\n",
    "    pattern = r\"Avg Altitude\\s*([\\d,]+)\\s*:\\s*([\\d,]+)\"\n",
    "    match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        avg_altitude_first = match.group(1).replace(',', '').strip()\n",
    "        avg_altitude_next = match.group(2).replace(',', '').strip()\n",
    "        extracted_data['Avg Altitude'] = avg_altitude_next + \" ft\"\n",
    "        extracted_data[\"Elevation Gain\"] = str(int(avg_altitude_next.replace(\" ft\", \"\")) - int(avg_altitude_first.replace(\" ft\", \"\"))) + \" ft\"\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Process the OCR text and lines\n",
    "data = process_text(text, lines)\n",
    "\n",
    "# Show the DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582fafb",
   "metadata": {},
   "source": [
    "# Processing the csv file extracted from the gps tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39feda47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Summary</th>\n",
       "      <th>Avg Altitude (ft)</th>\n",
       "      <th>Avg Speed (mph)</th>\n",
       "      <th>Distance (mile)</th>\n",
       "      <th>Elevation Gain</th>\n",
       "      <th>Date</th>\n",
       "      <th>Letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01h08m09s</td>\n",
       "      <td>930</td>\n",
       "      <td>47.5</td>\n",
       "      <td>53.9</td>\n",
       "      <td>-628 ft</td>\n",
       "      <td>2024-26-02</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 1h03m28s</td>\n",
       "      <td>939</td>\n",
       "      <td>54.</td>\n",
       "      <td>57.5</td>\n",
       "      <td>-651 ft</td>\n",
       "      <td>2024-27-02</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01h08m19s</td>\n",
       "      <td>918</td>\n",
       "      <td>47.6</td>\n",
       "      <td>54.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-29-02</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01h05m09s</td>\n",
       "      <td>946</td>\n",
       "      <td>49.5</td>\n",
       "      <td>53.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01h06m52s</td>\n",
       "      <td>941</td>\n",
       "      <td>48.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-14-03</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01h09m53s</td>\n",
       "      <td>937</td>\n",
       "      <td>46.3</td>\n",
       "      <td>53.9</td>\n",
       "      <td>-622 ft</td>\n",
       "      <td>2024-14-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01h40m59s</td>\n",
       "      <td>944</td>\n",
       "      <td>32.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-15-03</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01h07m41s</td>\n",
       "      <td>932</td>\n",
       "      <td>50.3</td>\n",
       "      <td>56.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-15-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01h04m58s</td>\n",
       "      <td>932</td>\n",
       "      <td>49.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>661 ft</td>\n",
       "      <td>2024-19-03</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0 1h08m27s</td>\n",
       "      <td>951</td>\n",
       "      <td>49.7</td>\n",
       "      <td>56.8</td>\n",
       "      <td>7930 ft</td>\n",
       "      <td>2024-20-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01h05m04s</td>\n",
       "      <td>935</td>\n",
       "      <td>52.9</td>\n",
       "      <td>57.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-21-03</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01h02m15s</td>\n",
       "      <td>939</td>\n",
       "      <td>50.2</td>\n",
       "      <td>52.1</td>\n",
       "      <td>-629 ft</td>\n",
       "      <td>2024-21-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01h29m47s</td>\n",
       "      <td>800</td>\n",
       "      <td>40.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>-518 ft</td>\n",
       "      <td>2024-22-03</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01h07m17s</td>\n",
       "      <td>935</td>\n",
       "      <td>48.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0 1h05m26s</td>\n",
       "      <td>930</td>\n",
       "      <td>49.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>-620 ft</td>\n",
       "      <td>2024-26-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01h09m37s</td>\n",
       "      <td>938</td>\n",
       "      <td>46.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>-622 ft</td>\n",
       "      <td>2024-27-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01h04m19s</td>\n",
       "      <td>960</td>\n",
       "      <td>53.6</td>\n",
       "      <td>57.5</td>\n",
       "      <td>-640 ft</td>\n",
       "      <td>2024-28-03</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01h09m51s</td>\n",
       "      <td>941</td>\n",
       "      <td>46.2</td>\n",
       "      <td>53.8</td>\n",
       "      <td>-624 ft</td>\n",
       "      <td>2024-28-03</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01h00m38s</td>\n",
       "      <td>865</td>\n",
       "      <td>63.7</td>\n",
       "      <td>64.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01h16m36s</td>\n",
       "      <td>933</td>\n",
       "      <td>42.5</td>\n",
       "      <td>54.3</td>\n",
       "      <td>-629 ft</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Summary Avg Altitude (ft) Avg Speed (mph) Distance (mile)  \\\n",
       "0     01h08m09s               930            47.5            53.9   \n",
       "1    0 1h03m28s               939             54.            57.5   \n",
       "2     01h08m19s               918            47.6            54.2   \n",
       "3     01h05m09s               946            49.5            53.8   \n",
       "4     01h06m52s               941            48.5            54.0   \n",
       "5     01h09m53s               937            46.3            53.9   \n",
       "6     01h40m59s               944            32.1            54.0   \n",
       "7     01h07m41s               932            50.3            56.7   \n",
       "8     01h04m58s               932            49.9            54.0   \n",
       "9    0 1h08m27s               951            49.7            56.8   \n",
       "10    01h05m04s               935            52.9            57.3   \n",
       "11    01h02m15s               939            50.2            52.1   \n",
       "12    01h29m47s               800            40.0            59.8   \n",
       "13    01h07m17s               935            48.0            53.9   \n",
       "14   0 1h05m26s               930            49.4            53.9   \n",
       "15    01h09m37s               938            46.4            53.9   \n",
       "16    01h04m19s               960            53.6            57.5   \n",
       "17    01h09m51s               941            46.2            53.8   \n",
       "18    01h00m38s               865            63.7            64.4   \n",
       "19    01h16m36s               933            42.5            54.3   \n",
       "\n",
       "   Elevation Gain        Date Letter  \n",
       "0         -628 ft  2024-26-02      B  \n",
       "1         -651 ft  2024-27-02      A  \n",
       "2             NaN  2024-29-02      A  \n",
       "3             NaN  2024-12-03      B  \n",
       "4             NaN  2024-14-03      A  \n",
       "5         -622 ft  2024-14-03      B  \n",
       "6             NaN  2024-15-03      A  \n",
       "7             NaN  2024-15-03      B  \n",
       "8          661 ft  2024-19-03      A  \n",
       "9         7930 ft  2024-20-03      B  \n",
       "10            NaN  2024-21-03      A  \n",
       "11        -629 ft  2024-21-03      B  \n",
       "12        -518 ft  2024-22-03      A  \n",
       "13            NaN  2024-25-03      B  \n",
       "14        -620 ft  2024-26-03      B  \n",
       "15        -622 ft  2024-27-03      B  \n",
       "16        -640 ft  2024-28-03      A  \n",
       "17        -624 ft  2024-28-03      B  \n",
       "18            NaN  2024-09-05      A  \n",
       "19        -629 ft  2024-09-05      B  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\msikh\\EV_Project\\EV_Discharging_Data\\NEUTC\\EV Trip Data\\Data_2\\GPS App\\Data_EV_trip_GPS_APP.csv'  # Replace with actual file path\n",
    "Data_EV_trip_GPS_APP = pd.read_csv(file_path)\n",
    "\n",
    "def extract_date_and_letter(trip_name):\n",
    "    match = re.match(r\"(\\d{2})(\\d{2})(\\d{2})([A-Z])\", trip_name)\n",
    "    if match:\n",
    "        day, month, year, letter = match.groups()\n",
    "        date = f\"20{year}-{month}-{day}\"\n",
    "        return date, letter\n",
    "    return trip_name, ''\n",
    "\n",
    "# Process the 'Trip Name' column\n",
    "if 'Trip Name' in Data_EV_trip_GPS_APP.columns:\n",
    "    Data_EV_trip_GPS_APP['Date'], Data_EV_trip_GPS_APP['Letter'] = zip(*Data_EV_trip_GPS_APP['Trip Name'].apply(extract_date_and_letter))\n",
    "    Data_EV_trip_GPS_APP.drop(columns=['Trip Name'], inplace=True)\n",
    "# Function to separate values and units\n",
    "def extract_value_and_unit(text):\n",
    "    if isinstance(text, str):\n",
    "        match = re.match(r\"([0-9.,]+)\\s*([a-zA-Z]+)\", text)\n",
    "        if match:\n",
    "            return match.groups()\n",
    "    return text, ''\n",
    "\n",
    "# List of columns to process\n",
    "columns_to_process = ['Avg Speed', 'Avg Altitude', 'Distance']  # Adjust these column names as needed\n",
    "\n",
    "# Process columns and update column names with units\n",
    "for column in columns_to_process:\n",
    "    if column in Data_EV_trip_GPS_APP.columns:\n",
    "        Data_EV_trip_GPS_APP[column], units = zip(*Data_EV_trip_GPS_APP[column].apply(extract_value_and_unit))\n",
    "        if units and units[0]:  # Ensure there is at least one unit detected\n",
    "            unit = units[0]\n",
    "            Data_EV_trip_GPS_APP.rename(columns={column: f\"{column} ({unit})\"}, inplace=True)\n",
    "\n",
    "Data_EV_trip_GPS_APP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1df88",
   "metadata": {},
   "source": [
    "# Processing Apple WAtches images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e67e42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['< History Wed, Apr 3 (4', '', 'Outdoor Cycle', 'x. Open Goal', '', 'O O 8:17 AM-9:27 AM', '', '4 Bristol', '', 'Workout Details Show More', '', 'Workout Time Elapsed Time', '1:05:42 1:10:11', 'Distance Active Calories', '53.89MI 196CAL', 'Total Calories Elevation Gain', '309CAL 3,077FT', 'Avg. Speed', '', '49.2MPH', '']\n",
      "['< History Tue, Apr 2 (4', '', 'Outdoor Cycle', 'x Open Goal', '', 'O O 7:02 AM-8:07 AM', '', '4 Bristol', '', 'Workout Details Show More', '', 'Workout Time Distance', '1:05:37 54.01mMI', 'Active Calories Total Calories', '201CAL 316CAL', 'Elevation Gain Avg. Speed', '', '2,966FT 49.3MPH', '']\n",
      "['Workout Time Distance', '1:05:37 54.01mMI', '201CAL 316CAL', 'Elevation Gain Avg. Speed', '2,966FT 49.3MPH']\n",
      "{'Distance': '54.01m miles', 'Avg Speed': '49.3 mph', 'Elevation Gain': '2,966 ft', 'Time Summary': '1:05:37'}\n"
     ]
    }
   ],
   "source": [
    "img_apple = Image.open(\"040324B.jpeg\")\n",
    "img_apple2 = Image.open(\"040224A_APPle.jpeg\")\n",
    "apple_text = pytesseract.image_to_string(img_apple)\n",
    "apple_text_2=pytesseract.image_to_string(img_apple2)\n",
    "lines_apple=apple_text.split(\"\\n\")\n",
    "lines_apple_2=apple_text_2.split(\"\\n\")\n",
    "print(lines_apple)\n",
    "print(lines_apple_2)\n",
    "\n",
    "# List of keywords to remove\n",
    "keywords = [\"Calories\", \"Workout Detail\", \"Open Goal\",\"History\",\"Bristol\",\"Outdoor\",\"AM\"]\n",
    "\n",
    "# Function to check if an element should be removed\n",
    "def should_remove(element):\n",
    "    if element == '':\n",
    "        return True\n",
    "    for keyword in keywords:\n",
    "        if re.search(keyword, element, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filter the list\n",
    "filtered_lines_apple = [element for element in lines_apple_2 if not should_remove(element)]\n",
    "\n",
    "# Display the filtered list\n",
    "print(filtered_lines_apple)\n",
    "\n",
    "# Initialize the dictionary to store the extracted values\n",
    "extracted_data = {}\n",
    "\n",
    "def extract_value(text, unit):\n",
    "    match = re.search(rf'([0-9.,a-zA-Z]+)\\s*{unit}', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Extract the distance\n",
    "for element in filtered_lines_apple:\n",
    "    distance = extract_value(element, 'MI')\n",
    "    if distance:\n",
    "        extracted_data['Distance'] = f'{distance} miles'\n",
    "        break\n",
    "\n",
    "# Extract the average speed\n",
    "for element in filtered_lines_apple:\n",
    "    avg_speed = extract_value(element, 'MPH')\n",
    "    if avg_speed:\n",
    "        extracted_data['Avg Speed'] = f'{avg_speed} mph'\n",
    "        break\n",
    "\n",
    "# Extract the elevation gain\n",
    "for element in filtered_lines_apple:\n",
    "    elevation_gain = extract_value(element, 'FT')\n",
    "    if elevation_gain:\n",
    "        extracted_data['Elevation Gain'] = f'{elevation_gain} ft'\n",
    "        break\n",
    "\n",
    "# Extract the time summary\n",
    "for element in filtered_lines_apple:\n",
    "    match = re.search(r'\\b(\\d{1,2}:\\d{2}:\\d{2})\\b', element)\n",
    "    if match:\n",
    "        extracted_data['Time Summary'] = match.group(1)\n",
    "        break\n",
    "\n",
    "# Display the extracted data\n",
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782bc9a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_1256\\1321971793.py:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:/Users/msikh/EV_Project/EV_Discharging_Data/NEUTC/EV Trip Data/Data_2/Apple Watch/Data_EV_trip_Apple_Watch.csv\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Setting the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Function to process the image and extract text\n",
    "def process_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image, lang='eng')\n",
    "    return text\n",
    "\n",
    "# List of keywords to remove\n",
    "keywords = [\"Calories\", \"Workout Detail\", \"Open Goal\", \"History\", \"Bristol\", \"Outdoor\", \"AM\"]\n",
    "\n",
    "# Function to check if an element should be removed\n",
    "def should_remove(element):\n",
    "    if element == '':\n",
    "        return True\n",
    "    for keyword in keywords:\n",
    "        if re.search(keyword, element, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract the value before a unit (handles numbers and letters)\n",
    "def extract_value(text, unit):\n",
    "    match = re.search(rf'([0-9.,a-zA-Z]+)\\s*{unit}', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Function to process text and extract relevant data\n",
    "def process_text(ocr_text):\n",
    "    lines = ocr_text.split(\"\\n\")\n",
    "    filtered_lines = [element for element in lines if not should_remove(element)]\n",
    "\n",
    "    # Initialize the dictionary to store the extracted values\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Extract the time summary\n",
    "    for element in filtered_lines:\n",
    "        match = re.search(r'\\b(\\d{1,2}:\\d{2}:\\d{2})\\b', element)\n",
    "        if match:\n",
    "            extracted_data['Time Summary'] = match.group(1)\n",
    "            break\n",
    "\n",
    "\n",
    "    # Extract the elevation gain\n",
    "    for element in filtered_lines:\n",
    "        elevation_gain = extract_value(element, 'FT')\n",
    "        if elevation_gain:\n",
    "            extracted_data['Elevation Gain'] = f'{elevation_gain} ft'\n",
    "            break\n",
    "         # Extract the average speed\n",
    "    for element in filtered_lines:\n",
    "        avg_speed = extract_value(element, 'MPH')\n",
    "        if avg_speed:\n",
    "            extracted_data['Avg Speed'] = f'{avg_speed} mph'\n",
    "            break\n",
    "       \n",
    "        # Extract the distance\n",
    "    for element in filtered_lines:\n",
    "        distance = extract_value(element, 'MI')\n",
    "        if distance:\n",
    "            extracted_data['Distance'] = f'{distance} miles'\n",
    "            break\n",
    "    return extracted_data\n",
    "\n",
    "# DataFrame to store all data cumulatively\n",
    "cumulative_data_df = pd.DataFrame()\n",
    "\n",
    "def upload_action():\n",
    "    file_paths = filedialog.askopenfilenames()\n",
    "    global cumulative_data_df\n",
    "    for path in file_paths:\n",
    "        text = process_image(path)\n",
    "        data = process_text(text)\n",
    "        data['Trip Name'] = os.path.basename(path)\n",
    "        cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
    "    \n",
    "    result_text.delete('1.0', tk.END)  # Clear existing text\n",
    "    result_text.insert(tk.END, cumulative_data_df.to_string(index=False))  # Display dataframe as string in text widget\n",
    "\n",
    "def save_csv():\n",
    "    save_path = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    if save_path:\n",
    "        global cumulative_data_df\n",
    "        cumulative_data_df.to_csv(save_path, index=False)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "        cumulative_data_df = pd.DataFrame()  # Reset DataFrame after saving\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"EV_IMAGE_TEXT_Extractor\")\n",
    "\n",
    "# Button to upload images\n",
    "upload_btn = tk.Button(root, text=\"Upload Images\", command=upload_action)\n",
    "upload_btn.pack()\n",
    "\n",
    "# Button to save CSV\n",
    "save_btn = tk.Button(root, text=\"Save CSV\", command=save_csv)\n",
    "save_btn.pack()\n",
    "\n",
    "# Text widget to display results\n",
    "result_text = tk.Text(root, height=20, width=80)\n",
    "result_text.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302bdcc3",
   "metadata": {},
   "source": [
    "# Processing the Apple watch CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4e1288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time Summary Elevation Gain (ft) Avg Speed (mph) Distance (miles)  \\\n",
      "0       1:06:46               2,996            48.2            53.65   \n",
      "1       1:03:20               3,149            53.5            56.52   \n",
      "2       1:08:02               2,847            47.6            54.04   \n",
      "3       1:05:43               2,968            49.3            54.03   \n",
      "4       1:06:38               2,900            48.6            54.00   \n",
      "5       1:09:41               2,961            46.1            53.57   \n",
      "6       1:10:14               2,766            46.1            54.05   \n",
      "7       1:07:24               3,162            50.5            56.82   \n",
      "8       1:04:38               2,819            50.1            54.07   \n",
      "9       1:08:44               3,105            49.5            56.74   \n",
      "10      1:06:07               3,056            51.8            57.18   \n",
      "11      1:02:21               3,060            50.2            52.22   \n",
      "12      1:30:16               3,033            39.4            59.31   \n",
      "13      1:06:52               3,007            48.3            53.93   \n",
      "14      1:05:12               3,112            49.6            53.91   \n",
      "15      1:09:22               2,987            46.6            53.94   \n",
      "16      1:04:04               2,995            53.0            56.63   \n",
      "17      1:09:38               2,934            46.4            53.91   \n",
      "18      1:00:26               2,884            62.5            62.96   \n",
      "19      1:16:28               3,030            42.3            53.95   \n",
      "\n",
      "          Date Letter  \n",
      "0   2024-26-02      B  \n",
      "1   2024-27-02      A  \n",
      "2   2024-29-02      A  \n",
      "3   2024-12-03      B  \n",
      "4   2024-14-03      A  \n",
      "5   2024-14-03      B  \n",
      "6   2024-15-03      A  \n",
      "7   2024-15-03      B  \n",
      "8   2024-19-03      A  \n",
      "9   2024-20-03      B  \n",
      "10  2024-21-03      A  \n",
      "11  2024-21-03      B  \n",
      "12  2024-22-03      A  \n",
      "13  2024-25-03      B  \n",
      "14  2024-26-03      B  \n",
      "15  2024-27-03      B  \n",
      "16  2024-28-03      A  \n",
      "17  2024-28-03      B  \n",
      "18  2024-09-05      A  \n",
      "19  2024-09-05      B  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Data_EV_trip_GPS_APP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(Data_EV_trip_Apple)\n\u001b[0;32m     40\u001b[0m Data_EV_trip_Apple\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_EV_trip_Apple.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mData_EV_trip_GPS_APP\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_EV_GPS_App.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Data_EV_trip_GPS_APP' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\msikh\\EV_Project\\EV_Discharging_Data\\NEUTC\\EV Trip Data\\Data_2\\Apple Watch\\Data_EV_trip_Apple_Watch.csv'  # Replace with actual file path\n",
    "Data_EV_trip_Apple = pd.read_csv(file_path)\n",
    "\n",
    "def extract_date_and_letter(trip_name):\n",
    "    match = re.match(r\"(\\d{2})(\\d{2})(\\d{2})([A-Z])\", trip_name)\n",
    "    if match:\n",
    "        day, month, year, letter = match.groups()\n",
    "        date = f\"20{year}-{month}-{day}\"\n",
    "        return date, letter\n",
    "    return trip_name, ''\n",
    "\n",
    "# Process the 'Trip Name' column\n",
    "if 'Trip Name' in Data_EV_trip_Apple.columns:\n",
    "    Data_EV_trip_Apple['Date'], Data_EV_trip_Apple['Letter'] = zip(*Data_EV_trip_Apple['Trip Name'].apply(extract_date_and_letter))\n",
    "    Data_EV_trip_Apple.drop(columns=['Trip Name'], inplace=True)\n",
    "# Function to separate values and units\n",
    "def extract_value_and_unit(text):\n",
    "    if isinstance(text, str):\n",
    "        match = re.match(r\"([0-9.,]+)\\s*([a-zA-Z]+)\", text)\n",
    "        if match:\n",
    "            return match.groups()\n",
    "    return text, ''\n",
    "\n",
    "# List of columns to process\n",
    "columns_to_process = ['Avg Speed', 'Elevation Gain', 'Distance']  # Adjust these column names as needed\n",
    "\n",
    "# Process columns and update column names with units\n",
    "for column in columns_to_process:\n",
    "    if column in Data_EV_trip_Apple.columns:\n",
    "        Data_EV_trip_Apple[column], units = zip(*Data_EV_trip_Apple[column].apply(extract_value_and_unit))\n",
    "        if units and units[0]:  # Ensure there is at least one unit detected\n",
    "            unit = units[0]\n",
    "            Data_EV_trip_Apple.rename(columns={column: f\"{column} ({unit})\"}, inplace=True)\n",
    "\n",
    "print(Data_EV_trip_Apple)\n",
    "Data_EV_trip_Apple.to_csv(\"Data_EV_trip_Apple.csv\")\n",
    "Data_EV_trip_GPS_APP.to_csv(\"Data_EV_GPS_App.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c75e3",
   "metadata": {},
   "source": [
    "# Plots comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f5f7df51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_GPS</th>\n",
       "      <th>Time Summary_GPS</th>\n",
       "      <th>Avg Altitude (ft)</th>\n",
       "      <th>Avg Speed_GPS</th>\n",
       "      <th>Distance_GPS</th>\n",
       "      <th>Date</th>\n",
       "      <th>Letter</th>\n",
       "      <th>Unnamed: 0_Apple</th>\n",
       "      <th>Time Summary_Apple</th>\n",
       "      <th>Elevation Gain (ft)</th>\n",
       "      <th>Avg Speed_Apple</th>\n",
       "      <th>Distance_Apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 1h05m29s</td>\n",
       "      <td>15416</td>\n",
       "      <td>49.7</td>\n",
       "      <td>54.2</td>\n",
       "      <td>2/4/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1:05:37</td>\n",
       "      <td>2,966</td>\n",
       "      <td>49.3</td>\n",
       "      <td>54.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0 1h07m27s</td>\n",
       "      <td>938</td>\n",
       "      <td>50.8</td>\n",
       "      <td>57.1</td>\n",
       "      <td>3/4/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1:07:12</td>\n",
       "      <td>3,039</td>\n",
       "      <td>50.5</td>\n",
       "      <td>56.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>01h05m55s</td>\n",
       "      <td>1,527</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>3/4/2024</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1:05:42</td>\n",
       "      <td>3,077</td>\n",
       "      <td>49,.2</td>\n",
       "      <td>53.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>01h16m51s</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>4/4/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>1:16:40</td>\n",
       "      <td>2,981</td>\n",
       "      <td>42.1</td>\n",
       "      <td>53.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>01h15m23s</td>\n",
       "      <td>1,581</td>\n",
       "      <td>46.9</td>\n",
       "      <td>58.9</td>\n",
       "      <td>9/4/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1:15:09</td>\n",
       "      <td>3,229</td>\n",
       "      <td>47</td>\n",
       "      <td>58.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>01h07m18s</td>\n",
       "      <td>940</td>\n",
       "      <td>48.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>9/4/2024</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>1:07:06</td>\n",
       "      <td>2,948</td>\n",
       "      <td>48.2</td>\n",
       "      <td>53.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>01h06m52s</td>\n",
       "      <td>1,601</td>\n",
       "      <td>49.0</td>\n",
       "      <td>54.6</td>\n",
       "      <td>11/4/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>1:06:41</td>\n",
       "      <td>2,680</td>\n",
       "      <td>50</td>\n",
       "      <td>55.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>01h08m42s</td>\n",
       "      <td>1614</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>11/4/2024</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>1:08:29</td>\n",
       "      <td>3,157</td>\n",
       "      <td>47.2</td>\n",
       "      <td>53.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>01h06m32s</td>\n",
       "      <td>937</td>\n",
       "      <td>50.9</td>\n",
       "      <td>56.4</td>\n",
       "      <td>12/4/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>1:06:16</td>\n",
       "      <td>2,092</td>\n",
       "      <td>50.8</td>\n",
       "      <td>56.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>01h06m25s</td>\n",
       "      <td>916</td>\n",
       "      <td>51.2</td>\n",
       "      <td>57.3</td>\n",
       "      <td>12/4/2024</td>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>1:06:46</td>\n",
       "      <td>2,976</td>\n",
       "      <td>50.8</td>\n",
       "      <td>56.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>01h14m11 s</td>\n",
       "      <td>952</td>\n",
       "      <td>48.6</td>\n",
       "      <td>60.1</td>\n",
       "      <td>2024-16-04</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>1:13:58</td>\n",
       "      <td>3,378</td>\n",
       "      <td>48.7</td>\n",
       "      <td>60.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>01h07m00s</td>\n",
       "      <td>950</td>\n",
       "      <td>48.1</td>\n",
       "      <td>54.2</td>\n",
       "      <td>2024-16-04</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>1:07:23</td>\n",
       "      <td>2,999</td>\n",
       "      <td>47.9</td>\n",
       "      <td>53.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>01 h06m48s</td>\n",
       "      <td>882</td>\n",
       "      <td>48.9</td>\n",
       "      <td>54.5</td>\n",
       "      <td>2024-17-04</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>1:06:35</td>\n",
       "      <td>2,117</td>\n",
       "      <td>48.8</td>\n",
       "      <td>54.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>01h07m03s</td>\n",
       "      <td>1,495</td>\n",
       "      <td>51.2</td>\n",
       "      <td>57.2</td>\n",
       "      <td>2024-17-04</td>\n",
       "      <td>B</td>\n",
       "      <td>13</td>\n",
       "      <td>1:06:46</td>\n",
       "      <td>3101</td>\n",
       "      <td>51.4</td>\n",
       "      <td>57.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>01h12m25s</td>\n",
       "      <td>952</td>\n",
       "      <td>74.2</td>\n",
       "      <td>57.6</td>\n",
       "      <td>2024-18-04</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "      <td>1:12:11</td>\n",
       "      <td>2,996</td>\n",
       "      <td>47.8</td>\n",
       "      <td>57.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>01 h30m27s</td>\n",
       "      <td>947</td>\n",
       "      <td>35.9</td>\n",
       "      <td>54.1</td>\n",
       "      <td>2024-18-04</td>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>1:30:07</td>\n",
       "      <td>3,047</td>\n",
       "      <td>36</td>\n",
       "      <td>54.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>01h09m39s</td>\n",
       "      <td>925</td>\n",
       "      <td>46.7</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2024-23-04</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>1:09:25</td>\n",
       "      <td>3,156</td>\n",
       "      <td>46.9</td>\n",
       "      <td>54.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>01h00m38s</td>\n",
       "      <td>1617</td>\n",
       "      <td>63.7</td>\n",
       "      <td>64.4</td>\n",
       "      <td>9/5/2024</td>\n",
       "      <td>A</td>\n",
       "      <td>17</td>\n",
       "      <td>1:00:26</td>\n",
       "      <td>2,884</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>01 h16m36s</td>\n",
       "      <td>933</td>\n",
       "      <td>42.5</td>\n",
       "      <td>54.3</td>\n",
       "      <td>9/5/2024</td>\n",
       "      <td>B</td>\n",
       "      <td>18</td>\n",
       "      <td>1:16:28</td>\n",
       "      <td>3,030</td>\n",
       "      <td>42.3</td>\n",
       "      <td>53.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0_GPS Time Summary_GPS Avg Altitude (ft)  Avg Speed_GPS  \\\n",
       "0                0       0 1h05m29s             15416           49.7   \n",
       "1                1       0 1h07m27s               938           50.8   \n",
       "2                2        01h05m55s             1,527           49.0   \n",
       "3                3        01h16m51s                 1           42.0   \n",
       "4                4        01h15m23s             1,581           46.9   \n",
       "5                5        01h07m18s               940           48.0   \n",
       "6                6        01h06m52s             1,601           49.0   \n",
       "7                7        01h08m42s              1614           47.0   \n",
       "8                8        01h06m32s               937           50.9   \n",
       "9                9        01h06m25s               916           51.2   \n",
       "10              10       01h14m11 s               952           48.6   \n",
       "11              11        01h07m00s               950           48.1   \n",
       "12              12       01 h06m48s               882           48.9   \n",
       "13              13        01h07m03s             1,495           51.2   \n",
       "14              14        01h12m25s               952           74.2   \n",
       "15              15       01 h30m27s               947           35.9   \n",
       "16              16        01h09m39s               925           46.7   \n",
       "17              17        01h00m38s              1617           63.7   \n",
       "18              18       01 h16m36s               933           42.5   \n",
       "\n",
       "    Distance_GPS        Date Letter  Unnamed: 0_Apple Time Summary_Apple  \\\n",
       "0           54.2    2/4/2024      A                 0            1:05:37   \n",
       "1           57.1    3/4/2024      A                 1            1:07:12   \n",
       "2           53.8    3/4/2024      B                 2            1:05:42   \n",
       "3           53.8    4/4/2024      A                 3            1:16:40   \n",
       "4           58.9    9/4/2024      A                 4            1:15:09   \n",
       "5           53.8    9/4/2024      B                 5            1:07:06   \n",
       "6           54.6   11/4/2024      A                 6            1:06:41   \n",
       "7           53.9   11/4/2024      B                 7            1:08:29   \n",
       "8           56.4   12/4/2024      A                 8            1:06:16   \n",
       "9           57.3   12/4/2024      B                 9            1:06:46   \n",
       "10          60.1  2024-16-04      A                10            1:13:58   \n",
       "11          54.2  2024-16-04      B                11            1:07:23   \n",
       "12          54.5  2024-17-04      A                12            1:06:35   \n",
       "13          57.2  2024-17-04      B                13            1:06:46   \n",
       "14          57.6  2024-18-04      A                14            1:12:11   \n",
       "15          54.1  2024-18-04      B                15            1:30:07   \n",
       "16          54.3  2024-23-04      A                16            1:09:25   \n",
       "17          64.4    9/5/2024      A                17            1:00:26   \n",
       "18          54.3    9/5/2024      B                18            1:16:28   \n",
       "\n",
       "   Elevation Gain (ft) Avg Speed_Apple  Distance_Apple  \n",
       "0                2,966            49.3           54.01  \n",
       "1                3,039            50.5           56.59  \n",
       "2                3,077           49,.2           53.89  \n",
       "3                2,981            42.1           53.92  \n",
       "4                3,229              47           58.97  \n",
       "5                2,948            48.2           53.92  \n",
       "6                2,680              50           55.61  \n",
       "7                3,157            47.2           53.91  \n",
       "8                2,092            50.8           56.18  \n",
       "9                2,976            50.8           56.55  \n",
       "10               3,378            48.7           60.03  \n",
       "11               2,999            47.9           53.94  \n",
       "12               2,117            48.8           54.20  \n",
       "13                3101            51.4           57.27  \n",
       "14               2,996            47.8           57.59  \n",
       "15               3,047              36           54.16  \n",
       "16               3,156            46.9           54.30  \n",
       "17               2,884            62.5           62.96  \n",
       "18               3,030            42.3           53.95  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1896696",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Avg Speed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Avg Speed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m data_apple \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path_apple)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#Make sure everything is a float\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m data_gps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Speed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdata_gps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAvg Speed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     14\u001b[0m data_apple[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Speed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data_apple[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Speed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Merge data on Date and Letter for comparison\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Avg Speed'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Load the two CSV files\n",
    "file_path_gps = 'Data_EV_GPS_App.csv'  # Replace with actual file path\n",
    "file_path_apple = 'Data_EV_trip_Apple.csv'  # Replace with actual file path\n",
    "\n",
    "data_gps = pd.read_csv(file_path_gps)\n",
    "data_apple = pd.read_csv(file_path_apple)\n",
    "\n",
    "#Make sure everything is a float\n",
    "data_gps['Avg Speed'] = pd.to_numeric(data_gps['Avg Speed'])\n",
    "data_apple['Avg Speed'] = pd.to_numeric(data_apple['Avg Speed'])\n",
    "\n",
    "# Merge data on Date and Letter for comparison\n",
    "merged_data = pd.merge(data_gps, data_apple, on=['Date', 'Letter'], suffixes=('_GPS', '_Apple'))\n",
    "\n",
    "# Plot comparison of distances\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_data['Date'] + merged_data['Letter'], merged_data['Distance_GPS'], label='GPS App', marker='o')\n",
    "plt.plot(merged_data['Date'] + merged_data['Letter'], merged_data['Distance_Apple'], label='Apple App', marker='x')\n",
    "plt.xlabel('Trip')\n",
    "plt.ylabel('Distance (miles)')\n",
    "plt.title('Comparison of Distances Between GPS App and Apple App')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot comparison of average speeds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_data['Date'] + merged_data['Letter'], merged_data['Avg Speed_GPS'], label='GPS App', marker='o')\n",
    "plt.plot(merged_data['Date'] + merged_data['Letter'], merged_data['Avg Speed_Apple'], label='Apple App', marker='x')\n",
    "plt.xlabel('Trip')\n",
    "plt.ylabel('Average Speed (mph)')\n",
    "plt.title('Comparison of Average Speeds Between GPS App and Apple App')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613ff8c",
   "metadata": {},
   "source": [
    "# Temp Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d061f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'80 °F'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the image from the file\n",
    "img = Image.open(\"052024A4.jpeg\")\n",
    "\n",
    "# Use pytesseract to do optical character recognition on the image\n",
    "temp_text = pytesseract.image_to_string(img, lang='eng')\n",
    "\n",
    "# Print the extracted text\n",
    "temp_text\n",
    "temp_lines=temp_text.split(\"\\n\")\n",
    "\n",
    "for element in temp_lines:\n",
    "    temperature = extract_value(element, '°F')\n",
    "    if temperature:\n",
    "        temp = f'{temperature} °F'\n",
    "        break\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8339e15",
   "metadata": {},
   "source": [
    "# Energy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434df1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since Last Charge Y Show in Trips Card\\nDistance Total Energy Avg. Energy\\n54 mi 13 kWh 244 Wh/mi\\nTp A. Reset & show nTips Card =\\nDistance Total Energy ‘Avg. Energy\\n4omi WkWh 233 Wh/mi\\nif Oa\\nTripB Reset ‘of 2 © w showin inps card\\nn Total/Energy Avg, Energy\\n6. 17 kWh 264 Wh/mi\\nOdometer : 63 mi show in Trips\\\\Card\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "# Load the image from the file\n",
    "img = Image.open(\"Data_Energy_1.jpg\")\n",
    "\n",
    "# Use pytesseract to do optical character recognition on the image\n",
    "Energy_text = pytesseract.image_to_string(img, lang='eng', config='--psm 6')\n",
    "\n",
    "# Print the extracted text\n",
    "Energy_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52dc684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Distance': '54 mi', 'Total Energy': '13 kWh', 'Avg Energy': '244 Wh'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Regex patterns to extract relevant data\n",
    "patterns = {\n",
    "    \"Distance\": r\"Energy\\s*([\\d\\.]+\\s*[a-zA-Z]+)\",\n",
    "    \"Total Energy\": r\"mi\\s*([\\d\\.]+\\s*[a-zA-Z]+)\",\n",
    "    \"Avg Energy\": r\"kWh\\s*([\\d\\.]+\\s*[a-zA-Z]+)\"\n",
    "}\n",
    "\n",
    "# Extracting and cleaning the data\n",
    "extracted_data = {}\n",
    "for key, pattern in patterns.items():\n",
    "    # Search using the pattern\n",
    "    match = re.search(pattern, Energy_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        value = match.group(1).strip()\n",
    "#         if key == \"Avg Speed\":\n",
    "#                 # Remove any unwanted prefix numbers followed by a period\n",
    "#                 value = re.sub(r\"^\\d+\\.\\d+\\s*\", \"\", value)\n",
    "#                 value= value.replace(\"Sinpn\",\"mph\")\n",
    "#                 value= value.replace(\" \",\".\")\n",
    "#                 value= value.replace(\"..\",\"\")\n",
    "#         if key in [\"Max Altitude\", \"Avg Altitude\"]:\n",
    "#             value = value.replace(\":\", \"\").strip() + \" ft\"  # Correct format and OCR error ':'\n",
    "        extracted_data[key] = value\n",
    "# pattern = r\"Avg Altitude\\s*([\\d,]+)\\s*:\\s*([\\d,]+)\"\n",
    "\n",
    "# # Search using the pattern\n",
    "# match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "# if match:\n",
    "#     avg_altitude_first = match.group(1).replace(',', '').strip()   # Clean up first number\n",
    "#     avg_altitude_next = match.group(2).replace(',', '').strip()  # Clean up second number\n",
    "\n",
    "# # # Display the cleaned data\n",
    "# extracted_data['Avg Altitude']= avg_altitude_next + \" ft\"\n",
    "# extracted_data[\"Elevation Gain\"]= str((int(avg_altitude_next) - int(avg_altitude_first) ))+ \" ft\"\n",
    "# patterns_2\n",
    "extracted_data\n",
    "# for key, pattern in patterns_2.items():\n",
    "#     # Search using the pattern\n",
    "#     match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "#     extracted_data[2+key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "516ed3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time Summary  Distance Avg Speed Max Altitude Avg Altitude Elevation Gain\n",
      "0  01 h09m51 s  53.8mile   46.5mph      1565 ft      9418 ft        7853 ft\n",
      "1  01 h09m00 s  53.9mile   46.5mph      1565 ft      9418 ft        7853 ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_25624\\3634173401.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data_df = extracted_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_25624\\3634173401.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data_df = extracted_data_df.append(data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Setting the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    invert = 255 - opening\n",
    "    text = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
    "    return text\n",
    "\n",
    "def upload_action():\n",
    "    file_path = filedialog.askopenfilenames()\n",
    "    extracted_texts = [process_image(path) for path in file_path]\n",
    "    result_text.delete('1.0', tk.END)  # Clear existing text\n",
    "    result_text.insert(tk.END, \"\\n\\n\".join(extracted_texts))\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Text Extractor\")\n",
    "\n",
    "# Button to upload images\n",
    "upload_btn = tk.Button(root, text=\"Upload Images\", command=upload_action)\n",
    "upload_btn.pack()\n",
    "\n",
    "# Text widget to display results\n",
    "result_text = tk.Text(root, height=20, width=80)\n",
    "result_text.pack()\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize DataFrame to store data\n",
    "data_columns = [\"Time Summary\", \"Distance\", \"Avg Speed\", \"Max Altitude\", \"Avg Altitude\", \"Elevation Gain\"]\n",
    "extracted_data_df = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "# Function to process text\n",
    "def process_text(ocr_text):\n",
    "    # Regex patterns to extract relevant data\n",
    "    patterns = {\n",
    "        \"Time Summary\": r\"Time Summary\\s*([\\d\\w\\s]+?)(?=\\n|$)\",\n",
    "        \"Distance\": r\"Distance\\s*([\\d\\.]+mile)\",\n",
    "        \"Avg Speed\": r\"Avg Speed\\s*([\\d\\.]+\\s*[a-zA-Z]+)\",\n",
    "        \"Max Altitude\": r\"Avg Altitude\\s*([\\d,]+)\",\n",
    "        \"Avg Speed\": r\"Avg Speed\\s*([\\d\\w\\s:.]+?)(?=\\n|$)\",\n",
    "        \"Avg Altitude\": r\"Avg Altitude\\s*([\\d,]+)\"\n",
    "    }\n",
    "\n",
    "    # Extracting and cleaning the data\n",
    "    extracted_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        # Search using the pattern\n",
    "        match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            if key == \"Avg Speed\":\n",
    "                value = re.sub(r\"^\\d+\\.\\d+\\s*\", \"\", value)  # Remove unwanted prefix numbers\n",
    "                value = value.replace(\"Sinpn\", \"mph\").replace(\" \", \".\").replace(\"..\", \"\")\n",
    "            if key in [\"Max Altitude\", \"Avg Altitude\"]:\n",
    "                value = value.replace(\":\", \"\").strip() + \" ft\"  # Correct format and OCR error\n",
    "            extracted_data[key] = value\n",
    "\n",
    "    # Further process for elevation gain\n",
    "    pattern = r\"Avg Altitude\\s*([\\d,]+)\\s*:\\s*([\\d,]+)\"\n",
    "    match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        avg_altitude_first = match.group(1).replace(',', '').strip()\n",
    "        avg_altitude_next = match.group(2).replace(',', '').strip()\n",
    "        extracted_data['Avg Altitude'] = avg_altitude_next + \" ft\"\n",
    "        extracted_data[\"Elevation Gain\"] = str(int(avg_altitude_next.replace(\" ft\", \"\")) - int(avg_altitude_first.replace(\" ft\", \"\"))) + \" ft\"\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Example texts list\n",
    "texts = [text1,text2]  # You can add more OCR texts to this list\n",
    "\n",
    "# Process each text and append results to DataFrame\n",
    "for text in texts:\n",
    "    data = process_text(text)\n",
    "    extracted_data_df = extracted_data_df.append(data, ignore_index=True)\n",
    "\n",
    "# Show the DataFrame\n",
    "print(extracted_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_25624\\2923305737.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_25624\\2923305737.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_25624\\2923305737.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
      "C:\\Users\\msikh\\AppData\\Local\\Temp\\ipykernel_25624\\2923305737.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:/Users/msikh/OneDrive - Norwich University/Desktop/Summer 2024/transportation Center Intern/EV_Sample.csv\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Setting the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    invert = 255 - opening\n",
    "    text = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
    "    return text\n",
    "\n",
    "def process_text(ocr_text):\n",
    "    # Regex patterns to extract relevant data\n",
    "    patterns = {\n",
    "        \"Time Summary\": r\"Time Summary\\s*([\\d\\w\\s]+?)(?=\\n|$)\",\n",
    "        \"Distance\": r\"Distance\\s*([\\d\\.]+mile)\",\n",
    "        \"Avg Speed\": r\"Avg Speed\\s*([\\d\\.]+\\s*[a-zA-Z]+)\",\n",
    "        \"Max Altitude\": r\"Avg Altitude\\s*([\\d,]+)\",\n",
    "        \"Avg Speed\": r\"Avg Speed\\s*([\\d\\w\\s:.]+?)(?=\\n|$)\",\n",
    "        \"Avg Altitude\": r\"Avg Altitude\\s*([\\d,]+)\"\n",
    "    }\n",
    "\n",
    "    # Extracting and cleaning the data\n",
    "    extracted_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        # Search using the pattern\n",
    "        match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            if key == \"Avg Speed\":\n",
    "                value = re.sub(r\"^\\d+\\.\\d+\\s*\", \"\", value)  # Remove unwanted prefix numbers\n",
    "                value = value.replace(\"Sinpn\", \"mph\").replace(\" \", \".\").replace(\"..\", \"\")\n",
    "            if key in [\"Max Altitude\", \"Avg Altitude\"]:\n",
    "                value = value.replace(\":\", \"\").strip() + \" ft\"  # Correct format and OCR error\n",
    "            extracted_data[key] = value\n",
    "\n",
    "    # Further process for elevation gain\n",
    "    pattern = r\"Avg Altitude\\s*([\\d,]+)\\s*:\\s*([\\d,]+)\"\n",
    "    match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        avg_altitude_first = match.group(1).replace(',', '').strip()\n",
    "        avg_altitude_next = match.group(2).replace(',', '').strip()\n",
    "        extracted_data['Avg Altitude'] = avg_altitude_next + \" ft\"\n",
    "        extracted_data[\"Elevation Gain\"] = str(int(avg_altitude_next.replace(\" ft\", \"\")) - int(avg_altitude_first.replace(\" ft\", \"\"))) + \" ft\"\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# DataFrame to store all data cumulatively\n",
    "cumulative_data_df = pd.DataFrame()\n",
    "\n",
    "def upload_action():\n",
    "    file_paths = filedialog.askopenfilenames()\n",
    "    global cumulative_data_df\n",
    "    for path in file_paths:\n",
    "        text = process_image(path)\n",
    "        data = process_text(text)\n",
    "        data['Image'] = os.path.basename(path)\n",
    "        cumulative_data_df = cumulative_data_df.append(data, ignore_index=True)\n",
    "    \n",
    "    result_text.delete('1.0', tk.END)  # Clear existing text\n",
    "    result_text.insert(tk.END, cumulative_data_df.to_string(index=False))  # Display dataframe as string in text widget\n",
    "\n",
    "def save_csv():\n",
    "    save_path = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    if save_path:\n",
    "        global cumulative_data_df\n",
    "        cumulative_data_df.to_csv(save_path, index=False)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "        cumulative_data_df = pd.DataFrame()  # Reset DataFrame after saving\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"EV_IMAGE_TEXT_Extractor\")\n",
    "\n",
    "# Button to upload images\n",
    "upload_btn = tk.Button(root, text=\"Upload Images\", command=upload_action)\n",
    "upload_btn.pack()\n",
    "\n",
    "# Button to save CSV\n",
    "save_btn = tk.Button(root, text=\"Save CSV\", command=save_csv)\n",
    "save_btn.pack()\n",
    "\n",
    "# Text widget to display results\n",
    "result_text = tk.Text(root, height=20, width=80)\n",
    "result_text.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00f88a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperatures on 2024-5-16 at KBTV: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_weather_data(station, date):\n",
    "    # Format the URL with the given station and date\n",
    "    url = f\"https://www.wunderground.com/history/daily/us/vt/south-burlington/{station}/date/{date}\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the temperature data (example selectors, may need adjustment)\n",
    "    temp_data = soup.find_all('<td', class_='ng-star-inserted')\n",
    "    \n",
    "    # Extract and print the temperatures\n",
    "    temperatures = [temp.text for temp in temp_data]\n",
    "    return temperatures\n",
    "\n",
    "# Example usage\n",
    "station_code = \"KBTV\"\n",
    "date = \"2024-5-16\"\n",
    "temperatures = get_weather_data(station_code, date)\n",
    "print(f\"Temperatures on {date} at {station_code}: {temperatures}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfad88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
